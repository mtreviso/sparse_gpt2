# Sparse GPT-2

Simple implementation of GPT-2 with sparse attention mechanism. 
Options of sparse attention mechanism are based on [alpha-entmax].


## How to use

Install the requirements: `pip install -r requirements.txt`.

And then run the following command:
```bash
python run_generation.py
```


